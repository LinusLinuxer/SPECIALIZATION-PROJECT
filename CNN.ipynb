{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd85a770",
   "metadata": {},
   "source": [
    "# CNN\n",
    "This notebook aims to deploy the CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "325a8a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ec81f6",
   "metadata": {},
   "source": [
    "---\n",
    "## Loading the data\n",
    "Data has to load out of the 'carolianminuscule-groundtruth'-folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "70206626",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(folder_path: str):\n",
    "    \"\"\"\n",
    "    Load images and text files from the given path.\n",
    "    :param folder_path: Path to the directory containing images and text files.\n",
    "    :return: Two lists - one for image paths and one for text file paths.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(folder_path):\n",
    "        raise FileNotFoundError(f\"Path {folder_path} does not exist.\")\n",
    "\n",
    "    images = []\n",
    "    files = []\n",
    "\n",
    "    for entry in os.listdir(folder_path):\n",
    "        entry_path = os.path.join(folder_path, entry)\n",
    "        if os.path.isdir(entry_path):\n",
    "            # Recursively get images and text files from subdirectories\n",
    "            sub_images, sub_files = get_images(entry_path)\n",
    "            images.extend(sub_images)\n",
    "            files.extend(sub_files)\n",
    "        elif entry.endswith(\".png\"):\n",
    "            images.append(entry_path)\n",
    "        elif entry.endswith(\".txt\"):\n",
    "            files.append(entry_path)\n",
    "\n",
    "    return images, files\n",
    "\n",
    "\n",
    "# load the data from the directory\n",
    "path = \"carolineminuscule-groundtruth\"\n",
    "images, files = get_images(path)\n",
    "\n",
    "\n",
    "# matched the .png- and .txt-file in a folder together\n",
    "matched_list_path = [\n",
    "    [img, file]\n",
    "    for img in images\n",
    "    for file in files\n",
    "    if os.path.dirname(img) == os.path.dirname(file)\n",
    "    and os.path.splitext(os.path.splitext(os.path.basename(img))[0])[0]\n",
    "    == os.path.splitext(os.path.splitext(os.path.basename(file))[0])[0]\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f715ff21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len matched: 429\n",
      "matched_list:\n",
      " ['carolineminuscule-groundtruth/bsb00095929/0011/010002.bin.png', 'carolineminuscule-groundtruth/bsb00095929/0011/010002.gt.txt']\n"
     ]
    }
   ],
   "source": [
    "print(f\"len matched: {len(matched_list_path)}\")\n",
    "print(f\"matched_list:\\n {matched_list_path[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8877200c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a dataframe to store the image, image paths and their corresponding text files\n",
    "df = pd.DataFrame(columns=[\"name\", \"image\", \"transcription\"])\n",
    "\n",
    "for i, (img_path, file_path) in enumerate(matched_list_path):\n",
    "    # read the image\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    _, img = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)\n",
    "    # convert the image to a numpy array\n",
    "    img = np.array(img)\n",
    "    # add the image to the dataframe, set \"none\" here to add transcription later\n",
    "    df.loc[i] = [os.path.basename(img_path), img, None]\n",
    "    # read the text file\n",
    "    with open(file_path, \"r\") as f:\n",
    "        # read the transcription\n",
    "        transcription = f.read()\n",
    "    # add the transcription to the dataframe\n",
    "    df.loc[i, \"transcription\"] = transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4f1c8f39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>image</th>\n",
       "      <th>transcription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>010005.bin.png</td>\n",
       "      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n",
       "      <td>initio sicuti pleriq; studio ad empabacan\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>010002.bin.png</td>\n",
       "      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n",
       "      <td>gla memores que s quis: faciliafacto putat\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>010007.bin.png</td>\n",
       "      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n",
       "      <td>pro abstinentia ꝓuirtute audacia. largitio. au...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>010008.bin.png</td>\n",
       "      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n",
       "      <td>bant. Quę tametsianimus aspꝑnabatur. insolens ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>010017.bin.png</td>\n",
       "      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n",
       "      <td>tilinę coniuratione quam uerissime potero pauc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             name                                              image  \\\n",
       "0  010005.bin.png  [[255, 255, 255, 255, 255, 255, 255, 255, 255,...   \n",
       "1  010002.bin.png  [[255, 255, 255, 255, 255, 255, 255, 255, 255,...   \n",
       "2  010007.bin.png  [[255, 255, 255, 255, 255, 255, 255, 255, 255,...   \n",
       "3  010008.bin.png  [[255, 255, 255, 255, 255, 255, 255, 255, 255,...   \n",
       "4  010017.bin.png  [[255, 255, 255, 255, 255, 255, 255, 255, 255,...   \n",
       "\n",
       "                                       transcription  \n",
       "0        initio sicuti pleriq; studio ad empabacan\\n  \n",
       "1       gla memores que s quis: faciliafacto putat\\n  \n",
       "2  pro abstinentia ꝓuirtute audacia. largitio. au...  \n",
       "3  bant. Quę tametsianimus aspꝑnabatur. insolens ...  \n",
       "4  tilinę coniuratione quam uerissime potero pauc...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47d708f",
   "metadata": {},
   "source": [
    "For now it appear that the images only have \"255\" as values, i.e. white. That's why im checking for other values. But the edges of the images are all white, therefore this is the exspected behaviour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ecfc47fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with values other than 255: 429\n"
     ]
    }
   ],
   "source": [
    "non_255_values = df['image'].apply(lambda img: np.any(img != 255))\n",
    "print(f\"Rows with values other than 255: {non_255_values.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "319becdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features (images) and labels (transcriptions)\n",
    "X = df['image'].values  # Images as NumPy arrays\n",
    "y = df['transcription'].values # Transcriptions as strings\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b79a41d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows in DataFrame: 429\n",
      "Rows with missing images: 0\n",
      "Rows with missing transcriptions: 0\n",
      "Number of samples in X: 429\n",
      "Number of samples in y: 429\n"
     ]
    }
   ],
   "source": [
    "# DEBUG\n",
    "# Check for missing data in the DataFrame\n",
    "print(f\"Total rows in DataFrame: {len(df)}\")\n",
    "print(f\"Rows with missing images: {df['image'].isnull().sum()}\")\n",
    "print(f\"Rows with missing transcriptions: {df['transcription'].isnull().sum()}\")\n",
    "\n",
    "# Drop rows with missing data\n",
    "df = df.dropna(subset=['image', 'transcription'])\n",
    "\n",
    "# Ensure all arrays have the same number of samples\n",
    "X = df['image'].values  # Images as NumPy arrays\n",
    "y = df['transcription'].values  # Transcriptions as strings\n",
    "\n",
    "print(f\"Number of samples in X: {len(X)}\")\n",
    "print(f\"Number of samples in y: {len(y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f5fe5092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">910</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10240</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m10\u001b[0m)     │           \u001b[38;5;34m100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m10\u001b[0m)     │           \u001b[38;5;34m910\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_4 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10240\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │     \u001b[38;5;34m1,024,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,010\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,026,120</span> (3.91 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,026,120\u001b[0m (3.91 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,026,120</span> (3.91 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,026,120\u001b[0m (3.91 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.Input(shape = (32, 32, 1)),\n",
    "    layers.Conv2D(10, kernel_size = (3, 3), padding = \"same\", activation = \"relu\"),\n",
    "    layers.Conv2D(10, kernel_size = (3, 3), padding = \"same\", activation = \"relu\"),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(100, activation = \"relu\"),\n",
    "    layers.Dense(10, activation = \"softmax\")\n",
    "])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "660556de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (343, 32, 32, 1)\n",
      "X_test shape: (86, 32, 32, 1)\n",
      "y_train shape: (16187, 42846)\n",
      "y_test shape: (4069, 42842)\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(),\n",
    "    loss=keras.losses.CategoricalCrossentropy(),\n",
    "    metrics=[keras.metrics.CategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "# Convert labels to categorical format\n",
    "y_train_categorical = keras.utils.to_categorical(\n",
    "    [ord(char) for char in \"\".join(y_train)]\n",
    ")\n",
    "y_test_categorical = keras.utils.to_categorical(\n",
    "    [ord(char) for char in \"\".join(y_test)]\n",
    ")\n",
    "\n",
    "# Reshape the images to match the input shape of the model\n",
    "X_train_reshaped = np.array(\n",
    "    [cv2.resize(img, (32, 32)).reshape(32, 32, 1) for img in X_train]\n",
    ")\n",
    "X_test_reshaped = np.array(\n",
    "    [cv2.resize(img, (32, 32)).reshape(32, 32, 1) for img in X_test]\n",
    ")\n",
    "\n",
    "\n",
    "#DEBUG\n",
    "print(f\"X_train shape: {X_train_reshaped.shape}\")\n",
    "print(f\"X_test shape: {X_test_reshaped.shape}\")\n",
    "print(f\"y_train shape: {y_train_categorical.shape}\")\n",
    "print(f\"y_test shape: {y_test_categorical.shape}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad05303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "model.fit(\n",
    "    X_train_reshaped,\n",
    "    y_train_categorical,\n",
    "    epochs=10,\n",
    "    validation_data=(X_test_reshaped, y_test_categorical),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
